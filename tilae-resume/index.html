<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Unity WebGL Player | Tilae</title>
    <link rel="shortcut icon" href="TemplateData/favicon.ico">
    <link rel="stylesheet" href="TemplateData/style.css">
    <script src="TemplateData/UnityProgress.js"></script>  
    <script src="Build/UnityLoader.js"></script>
    <script>
      var gameInstance = UnityLoader.instantiate("gameContainer", "Build/WebGL Build Base.json", {onProgress: UnityProgress});
    </script>
  </head>
  <body>
    <div class="webgl-content">
      <div id="gameContainer" style="width: 960px; height: 540px"></div>
      <div class="footer">
        <div class="webgl-logo"></div>
        <div class="fullscreen" onclick="gameInstance.SetFullscreen(1)"></div>
      </div>
    </div>
    <div class="description-content">
      <h2>Design Considerations</h2>
      <ul>
        <li>"Easy to learn, difficult to master" board game</li>
        <li>Increased accessibiity for players with vision impairments</li>
        <li>An AI that is not a master of the game</li>
      </ul>
      <h2>Coding Process</h2>
      <h3>Audio</h3>
      <div class="section-description">
        <p>In order to better accomodate visually impaired players, we needed to make use of audio cues to communicate UI and game states.  We listed what that would mean:</p>
        <ul>
          <li>Interactable portions of the UI need audio cues when a pointer enters.</li>
          <li>Any state change on the UI needs to communicate the nature of that change.</li>
          <li>Since the game board is made of multiple cells, each cell needs to communicate its state via unique sounds.</li>
          <li>Each player needs a unique sound that can be used as a cue for turn order.</li>
        </ul>
        <p>For the UI we decided voiceover would be the best, while for the playable portions we decided to use a base note for each cell on the board which would be modified by the cell's state.  As a result of these decisions we found we needed more sounds than usual for a project of this size, along with a means of managing them that would be relatively easy.  I wrote a simple audio managment system to accomplish this goal.  The system is built on a custom asset (SoundLibrary) which contains a Dictionary with custom serialization.  The SoundLibrary can be queueried for a sound by name so by adhering to a solid naming convention finding sounds on the board is easy.  A sound is then applied to a relevant AudioSource and played once found.</p>
        <iframe src="https://drive.google.com/file/d/13AS9bJ2oDpTLirPhsr6cdRCgqSGLPiRz/preview" width="640" height="480"></iframe>
      </div>
      <h3>AI</h3>
      <div class="section-description">
        <p>We decided to use a simple decision-making process for the AI that sought to make the best play based on</p>
      </div>
    </div>
  </body>
</html>